{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrhU+WTux7s8DHSc3uhUxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJAbuNasser/Final-Project/blob/main/Playing_w_the_assig.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "-EF0wnOdYLZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_posthocs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN08RfCFYS2H",
        "outputId": "8d28ef93-b7a9-4dfd-87f1-90e696fcc944"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit_posthocs in /usr/local/lib/python3.10/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (1.13.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (0.14.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from scikit_posthocs) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit_posthocs) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->scikit_posthocs) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit_posthocs) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind, shapiro, wilcoxon, friedmanchisquare\n",
        "import scikit_posthocs as sp\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "lg8HeIT2YKzE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Core Work**"
      ],
      "metadata": {
        "id": "KEHg5UfPYKiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data, title_prefix):\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
        "    sns.histplot(data, bins=20, kde=True, ax=axes[0])\n",
        "    axes[0].set_title(f'{title_prefix} Histogram - KDE')\n",
        "    sns.boxplot(data=data, ax=axes[1])\n",
        "    axes[1].set_title(f'{title_prefix} Boxplot')\n",
        "    sns.violinplot(data=data, ax=axes[2])\n",
        "    axes[2].set_title(f'{title_prefix} Violin Plot')\n",
        "    sns.scatterplot(x=range(len(data)), y=data, ax=axes[3])\n",
        "    axes[3].set_title(f'{title_prefix} Scatter Plot')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return fig, axes"
      ],
      "metadata": {
        "id": "tgljttJ0YKPk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_normality(data):\n",
        "    results = {}\n",
        "    for group, values in data.items():\n",
        "        if len(values) >= 3:\n",
        "            stat, p_value = shapiro(values)\n",
        "            results[group] = p_value > 0.05\n",
        "        else:\n",
        "            results[group] = None\n",
        "    return results"
      ],
      "metadata": {
        "id": "9zFgzs3IYZed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ttest(data, reference):\n",
        "    results = {}\n",
        "    for group, values in data.items():\n",
        "        if group != reference and len(data[reference]) == len(values):\n",
        "            stat, p_value = ttest_ind(data[reference], values)\n",
        "            results[group] = p_value\n",
        "    return results"
      ],
      "metadata": {
        "id": "zwLClngFasy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_wilcoxon(data, reference):\n",
        "    results = {}\n",
        "    for group, values in data.items():\n",
        "        if group != reference and len(data[reference]) == len(values):\n",
        "            stat, p_value = wilcoxon(data[reference], values)\n",
        "            results[group] = p_value\n",
        "    return results"
      ],
      "metadata": {
        "id": "jKMp2NOdav0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_friedman(data):\n",
        "    values = [data[group] for group in data]\n",
        "    stat, p_value = friedmanchisquare(*values)\n",
        "    return stat, p_value"
      ],
      "metadata": {
        "id": "HffKggWhay7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def post_hoc_analysis(data, alpha=0.05):\n",
        "    groups = list(data.keys())\n",
        "    data_array = np.array([data[group] for group in groups]).T\n",
        "    bonferroni = sp.posthoc_dunn(data_array, p_adjust='bonferroni')\n",
        "    holm = sp.posthoc_dunn(data_array, p_adjust='holm')\n",
        "    holland = sp.posthoc_dunn(data_array, p_adjust='holland')\n",
        "    hochberg = sp.posthoc_dunn(data_array, p_adjust='hochberg')\n",
        "    hommel = sp.posthoc_dunn(data_array, p_adjust='hommel')\n",
        "    return {\n",
        "        'Bonferroni': bonferroni,\n",
        "        'Holm': holm,\n",
        "        'Holland': holland,\n",
        "        'Hochberg': hochberg,\n",
        "        'Hommel': hommel\n",
        "    }"
      ],
      "metadata": {
        "id": "hVmMPw7ha2oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_txt(file, actual_file, algorithm_folder):\n",
        "    data = np.loadtxt(file, delimiter=' ')\n",
        "    actual = np.loadtxt(actual_file, delimiter=' ')\n",
        "    merrors = data - actual\n",
        "    return {algorithm_folder: merrors.tolist()}"
      ],
      "metadata": {
        "id": "j0yGHluCa6nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_xlsx(file, actual_file, algorithm_folder):\n",
        "    df = pd.read_excel(file, sheet_name=None)\n",
        "    actual = pd.read_excel(actual_file, sheet_name=None)\n",
        "    merrors = {}\n",
        "    for sheet_name, sheet_df in df.items():\n",
        "        actual_sheet = actual[sheet_name]\n",
        "        merrors[sheet_name] = (sheet_df.iloc[:, 1] - actual_sheet.iloc[:, 1]).tolist()\n",
        "    return {f\"{algorithm_folder}_{sheet_name}\": value for sheet_name, value in merrors.items()}"
      ],
      "metadata": {
        "id": "SFB-CCSSa9qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_grouped_data(data, reference_group, output_file_prefix, use_summary_files=False):\n",
        "    if use_summary_files:\n",
        "        summary_file = f\"{output_file_prefix}_Summary.xlsx\"\n",
        "        summary_df = pd.read_excel(summary_file)\n",
        "        summarized_data = {row['Group']: [row['Mean Error']] for index, row in summary_df.iterrows()}\n",
        "\n",
        "    else:\n",
        "        summarized_data = data\n",
        "\n",
        "    summary = []\n",
        "    for group, values in summarized_data.items():\n",
        "        summary.append({\n",
        "            \"Group\": group,\n",
        "            \"Mean Error\": np.mean(values),\n",
        "            \"Std Dev\": np.std(values),\n",
        "            \"Normality\": test_normality({group: values})[group]\n",
        "        })\n",
        "\n",
        "    friedman_stat, friedman_p = perform_friedman(summarized_data)\n",
        "    wilcoxon_results = perform_wilcoxon(summarized_data, reference_group)\n",
        "    post_hoc_results = post_hoc_analysis(summarized_data)\n",
        "\n",
        "    summary_df = pd.DataFrame(summary)\n",
        "    summary_df.to_excel(f\"{output_file_prefix}_Summary.xlsx\", index=False)\n",
        "\n",
        "    for method, results_df in post_hoc_results.items():\n",
        "        results_df.to_excel(f\"{output_file_prefix}_PostHoc_{method}.xlsx\", index=True)"
      ],
      "metadata": {
        "id": "F4wKfb9VbA7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_zip(data_zip_path, actual_values_zip_path, use_summary_files=False):\n",
        "    with zipfile.ZipFile(data_zip_path, 'r') as data_zip, zipfile.ZipFile(actual_values_zip_path, 'r') as actual_zip:\n",
        "        for folder in [\"10-D\", \"20-D\"]:\n",
        "            files_by_folder = {file.split('/')[0]: [] for file in data_zip.namelist() if folder in file}\n",
        "            for file in data_zip.namelist():\n",
        "                if folder in file:\n",
        "                    files_by_folder[file.split('/')[0]].append(file)\n",
        "            for algorithm_folder, files in files_by_folder.items():\n",
        "                reference_group = None\n",
        "                for i, file in enumerate(files):\n",
        "                    if file in data_zip.namelist() and file in actual_zip.namelist():\n",
        "                        folder_name = file.split('/')[0]\n",
        "                        if file.endswith('.txt'):\n",
        "                            with data_zip.open(file) as f, actual_zip.open(file) as af:\n",
        "                                data = process_txt(f, af, f\"{algorithm_folder}_{folder}_{i}\")\n",
        "                        elif file.endswith('.xlsx'):\n",
        "                            with data_zip.open(file) as f, actual_zip.open(file) as af:\n",
        "                                data = process_xlsx(f, af, f\"{algorithm_folder}_{folder}_{i}\")\n",
        "\n",
        "                        if i == 0:\n",
        "                            reference_group = list(data.keys())[0]\n",
        "\n",
        "                        output_file_prefix = f\"{algorithm_folder}_{folder}_Analysis_{i}\"\n",
        "                        analyze_grouped_data(data, reference_group, output_file_prefix, use_summary_files)"
      ],
      "metadata": {
        "id": "Tt_24BaRbFaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_zip(\"Data-All Algos.zip\", \"Actual Values.zip\", use_summary_files=True)"
      ],
      "metadata": {
        "id": "IU_U7tQlbJ3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}